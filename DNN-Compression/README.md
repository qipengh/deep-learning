# 模型压缩：Deep Compression

以剪枝和量化为主要压缩方式减小模型大小和计算量，使得模型可以应用在计算和存储资源有限的嵌入式等设备上。

## 剪枝Pruning
### 资料
* [博客：深度学习模型压缩方法（3）-----模型剪枝（Pruning）](https://blog.csdn.net/shentanyue/article/details/83539359)
* [博客：深度学习剪枝](https://blog.csdn.net/jacke121/article/details/79450321)

### 应用
* pass

## 量化Quantification
### 资料
* pass

### 应用
* [Caffe： Ristretto量化工具](http://lepsucd.com/?page_id=621)
* [TensorFlow Lite量化模型](https://tensorflow.google.cn/lite/models)
